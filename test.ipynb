{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.index import create_in, open_dir\n",
    "from whoosh.fields import *\n",
    "from whoosh.qparser import QueryParser\n",
    "from whoosh import scoring\n",
    "from whoosh.analysis import StemmingAnalyzer\n",
    "from whoosh.analysis import StandardAnalyzer\n",
    "from whoosh.analysis import RegexTokenizer\n",
    "from whoosh.analysis import LowercaseFilter\n",
    "from whoosh.analysis import StopFilter\n",
    "from whoosh.analysis import StemFilter\n",
    "from whoosh.analysis import NgramFilter\n",
    "from whoosh.analysis import Tokenizer\n",
    "from whoosh.analysis import Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema(title=TEXT(stored=True), path=ID(stored=True), content=TEXT(stored=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index\n",
    "ix = create_in(\"index\", schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyIndexError",
     "evalue": "Index 'MAIN' does not exist in FileStorage('index')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyIndexError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Open the index\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ix \u001b[39m=\u001b[39m open_dir(\u001b[39m\"\u001b[39;49m\u001b[39mindex\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Create a writer\u001b[39;00m\n\u001b[0;32m      5\u001b[0m writer \u001b[39m=\u001b[39m ix\u001b[39m.\u001b[39mwriter()\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\Desktop\\IR\\myenv\\lib\\site-packages\\whoosh\\index.py:123\u001b[0m, in \u001b[0;36mopen_dir\u001b[1;34m(dirname, indexname, readonly, schema)\u001b[0m\n\u001b[0;32m    121\u001b[0m     indexname \u001b[39m=\u001b[39m _DEF_INDEX_NAME\n\u001b[0;32m    122\u001b[0m storage \u001b[39m=\u001b[39m FileStorage(dirname, readonly\u001b[39m=\u001b[39mreadonly)\n\u001b[1;32m--> 123\u001b[0m \u001b[39mreturn\u001b[39;00m FileIndex(storage, schema\u001b[39m=\u001b[39;49mschema, indexname\u001b[39m=\u001b[39;49mindexname)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\Desktop\\IR\\myenv\\lib\\site-packages\\whoosh\\index.py:421\u001b[0m, in \u001b[0;36mFileIndex.__init__\u001b[1;34m(self, storage, schema, indexname)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindexname \u001b[39m=\u001b[39m indexname\n\u001b[0;32m    420\u001b[0m \u001b[39m# Try reading the TOC to see if it's possible\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m TOC\u001b[39m.\u001b[39;49mread(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindexname, schema\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_schema)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\Desktop\\IR\\myenv\\lib\\site-packages\\whoosh\\index.py:618\u001b[0m, in \u001b[0;36mTOC.read\u001b[1;34m(cls, storage, indexname, gen, schema)\u001b[0m\n\u001b[0;32m    616\u001b[0m     gen \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_latest_generation(storage, indexname)\n\u001b[0;32m    617\u001b[0m     \u001b[39mif\u001b[39;00m gen \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 618\u001b[0m         \u001b[39mraise\u001b[39;00m EmptyIndexError(\u001b[39m\"\u001b[39m\u001b[39mIndex \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m does not exist in \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    619\u001b[0m                               \u001b[39m%\u001b[39m (indexname, storage))\n\u001b[0;32m    621\u001b[0m \u001b[39m# Read the content of this index from the .toc file.\u001b[39;00m\n\u001b[0;32m    622\u001b[0m tocfilename \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_filename(indexname, gen)\n",
      "\u001b[1;31mEmptyIndexError\u001b[0m: Index 'MAIN' does not exist in FileStorage('index')"
     ]
    }
   ],
   "source": [
    "# Open the index\n",
    "ix = open_dir(\"index\")\n",
    "\n",
    "# Create a writer\n",
    "writer = ix.writer()\n",
    "\n",
    "# Add documents to the index\n",
    "writer.add_document(title=u\"First document\", path=u\"/a\", content=u\"This is the first document we've added!\")\n",
    "writer.add_document(title=u\"First document2\", path=u\"/a2\", content=u\"This is a sooo fucking long phrase!\")\n",
    "\n",
    "# Commit the changes\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Hit {'content': 'This is a sooo fucking long phrase!', 'path': '/a2', 'title': 'First document2'}>\n"
     ]
    }
   ],
   "source": [
    "# Create a searcher\n",
    "with ix.searcher() as searcher:\n",
    "    # Create a query parser\n",
    "    parser = QueryParser(\"content\", ix.schema)\n",
    "\n",
    "    # Parse the query\n",
    "    query = parser.parse(\"sooo\")\n",
    "\n",
    "    # Search the index\n",
    "    results = searcher.search(query)\n",
    "\n",
    "    # Print the results\n",
    "    print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for query 'book cover':\n",
      "Matching document: Document 1\n",
      "Matching document: Document 1\n",
      "Matching document: Document 1\n",
      "Matching document: Document 1\n",
      "Matching document: Document 1\n",
      "Matching document: Document 1\n",
      "Matching document: Document 1\n",
      "Matching document: Document 1\n"
     ]
    }
   ],
   "source": [
    "# Open the index\n",
    "ix = open_dir(\"index\")\n",
    "\n",
    "# Create a writer\n",
    "writer = ix.writer()\n",
    "\n",
    "# Add documents to the index\n",
    "writer.add_document(title=u\"Document 1\", path=u\"/1\", \n",
    "                    content=u\"This is the book's cover. Itâ€™s an example of possessive constructions and contractions.\")\n",
    "writer.add_document(title=u\"Document 2\", path=u\"/2\", \n",
    "                    content=u\"This co-education system is state-of-the-art.\")\n",
    "writer.add_document(title=u\"Document 3\", path=u\"/3\", \n",
    "                    content=u\"Meet Mr. Smith from the U.S.A.\")\n",
    "writer.add_document(title=u\"Document 4\", path=u\"/4\", \n",
    "                    content=u\"The date 3/12/91 is written in a different format.\")\n",
    "writer.add_document(title=u\"Document 5\", path=u\"/5\", \n",
    "                    content=u\"C++ and C# are programming languages.\")\n",
    "writer.add_document(title=u\"Document 6\", path=u\"/6\", \n",
    "                    content=u\"This document has stop words. They are usually common words.\")\n",
    "writer.add_document(title=u\"Document 7\", path=u\"/7\", \n",
    "                    content=u\"Anti-discriminatory laws exist. Color is the American spelling.\")\n",
    "writer.add_document(title=u\"Document 8\", path=u\"/8\", \n",
    "                    content=u\"People are reading books. The cars' colors are different.\")\n",
    "writer.add_document(title=u\"Document 9\", path=u\"/9\", \n",
    "                    content=u\"The process of replacement is ongoing.\")\n",
    "\n",
    "# Commit the changes\n",
    "writer.commit()\n",
    "\n",
    "results = [] \n",
    "\n",
    "# Create a searcher\n",
    "with ix.searcher() as searcher:\n",
    "    \n",
    "    # Create a query parser\n",
    "    parser = QueryParser(\"content\", ix.schema)\n",
    "    query_text = \"book cover\"\n",
    "    query = parser.parse(query_text)\n",
    "    # Search the index\n",
    "    results = searcher.search(query)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Results for query '{query_text}':\")\n",
    "    for hit in results:\n",
    "        print(\"Matching document:\", hit['title'])    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of queries to test\n",
    "queries = [\"book cover\", \"it is\", \"co education\", \"state of the art\", \"Mr Smith\", \"USA\", \n",
    "           \"Mar 12 1991\", \"C++\", \"C#\", \"stop words\", \"antidiscriminatory\", \"color\", \"be\", \"car\", \n",
    "           \"replace\"]\n",
    "\n",
    "# Create a searcher\n",
    "with ix.searcher() as searcher:\n",
    "    # Create a query parser\n",
    "    parser = QueryParser(\"content\", ix.schema)\n",
    "\n",
    "    for query_text in queries:\n",
    "        \n",
    "        # Parse the query\n",
    "        query = parser.parse(query_text)\n",
    "        print(\"query_text: \", query_text)\n",
    "\n",
    "        # Search the index\n",
    "        results = searcher.search(query)\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Results for query '{query_text}':\")\n",
    "        for hit in results:\n",
    "            print(\"Matching document:\", hit['title'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LASE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
